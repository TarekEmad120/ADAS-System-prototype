{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils  \n",
    "import cv2  \n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\CUFE\\\\GP\\\\Sleep_detection\\\\archive\\\\mrleyedataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31144\\2360402976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"D:\\CUFE\\GP\\Sleep_detection\\archive\\mrleyedataset\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class Mapping:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31144\\2360402976.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(dataset_path, target_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mclass_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\CUFE\\\\GP\\\\Sleep_detection\\\\archive\\\\mrleyedataset'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_path, target_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    * Service Name: load_dataset\n",
    "    * Sync/Async: Synchronous\n",
    "    * Reentrancy: Reentrant\n",
    "    * Parameters (in): dataset_path , target_size\n",
    "    * Parameters (inout): None\n",
    "    * Parameters (out): features, labels, class_mapping\n",
    "    * Return value: tuple\n",
    "    * Description: Loads the dataset from the specified path, preprocesses the images\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_mapping = {}\n",
    "\n",
    "    \"\"\"\n",
    "    in this part we are loading the dataset from the specified path\n",
    "    and preprocessing the images to extract features using HOG (Histogram of Oriented Gradients).\n",
    "    then we append the features and labels to their respective lists.\n",
    "    \"\"\"\n",
    "    class_names = sorted(os.listdir(dataset_path)) \n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        class_mapping[class_name] = idx  \n",
    "\n",
    "    for class_name, label in class_mapping.items():\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        for file_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, file_name)\n",
    "            preprocessed_image = preprocess_image_fromPath(image_path, target_size)\n",
    "            feature_vector = extract_hog_features(preprocessed_image)\n",
    "            features.append(feature_vector)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(features), np.array(labels), class_mapping\n",
    "\"\"\"\n",
    "here we ar loading the dataset from the specified path\n",
    "and then split the dataset into training and testing sets.\n",
    "\"\"\"\n",
    "\n",
    "dataset_path = r\"D:\\CUFE\\GP\\Sleep_detection\\archive\\mrleyedataset\"\n",
    "X, y, class_mapping = load_dataset(dataset_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Class Mapping:\", class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "in this part we will save the data in pickle files\n",
    "\"\"\"\n",
    "\n",
    "pickle_in = open(\"class_mapping.pickle\",\"rb\")\n",
    "class_mapping = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"X_train.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"X_test.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"class_mapping.pickle\",\"rb\")\n",
    "class_mapping = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "in this part we will train a Support Vector Machine (SVM) model using the training data and evaluate its performance on the test data.\n",
    "in which we will try to fit the SVM model to the training data and then predict the labels for the test data.\n",
    "\"\"\"\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVM Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'SVM_model.sav'\n",
    "# pickle.dump(svm_model, open(filename, 'wb'))\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Open-Eyes\n"
     ]
    }
   ],
   "source": [
    "# prdicting the image\n",
    "image_path = r\"D:\\CUFE\\GP\\Sleep_detection\\archive\\open_eye.jpg\"\n",
    "predicted_class = predict_image_fromPath(image_path, loaded_model, class_mapping)\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n",
      "Error in prediction\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31144\\1385255411.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time\n",
    "import winsound\n",
    "\n",
    "\"\"\" Variables to track closed eye duration \"\"\"\n",
    "closed_eye_start_time = None\n",
    "closed_eye_duration = 0\n",
    "CLOSED_EYE_THRESHOLD = 3  \n",
    "\n",
    "\"\"\" variable to track open eye duration\"\"\"\n",
    "open_eye_start_time = None\n",
    "open_eye_duration = 0\n",
    "OPEN_EYE_THRESHOLD = 1 \n",
    "\n",
    "\"\"\" variables to track side face duration \"\"\"\n",
    "side_face_start_time = None\n",
    "side_face_duration = 0\n",
    "SIDE_FACE_THRESHOLD = 3 \n",
    "\"\"\" Dlib face detector and predictor \"\"\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "#this model needed to be downloaded\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  \n",
    "\n",
    "cap = cv2.VideoCapture(0)  \n",
    "# this is important class in which we will use kalman filter to smooth the yaw angle\n",
    "class KalmanFilter:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        * Service Name: KalmanFilter\n",
    "        * Sync/Async: Synchronous\n",
    "        * Reentrancy: Reentrant\n",
    "        * Parameters (in): None\n",
    "        * Parameters (inout): None\n",
    "        * Parameters (out): None\n",
    "        \"\"\"\n",
    "        self.kalman = cv2.KalmanFilter(2, 1)\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 1], [0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.array([[1, 0], [0, 1e-5]], np.float32)\n",
    "        self.kalman.statePre = np.array([[0], [0]], np.float32)\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        * Service Name: update\n",
    "        * Sync/Async: Synchronous\n",
    "        * Reentrancy: Reentrant\n",
    "        * Parameters (in): measurement\n",
    "        * Parameters (inout): None\n",
    "        * Parameters (out): estimate\n",
    "        * Return value: float\n",
    "        \"\"\"\n",
    "        prediction = self.kalman.predict()\n",
    "        estimate = self.kalman.correct(np.array([[measurement]], np.float32))\n",
    "        return estimate[0][0]\n",
    "\n",
    "kalman_filter = KalmanFilter()\n",
    "\n",
    "while True:\n",
    "    \"\"\"\n",
    "    how this part works:\n",
    "    this part i susing Dlib to detect the face and facial landmarks\n",
    "    thus it will help us to detect eyes and capture it then crops it to pass to\n",
    "    the loaded SVM model to classify if the eyes are open or closed\n",
    "    if the eyes arn't found it will calaculate the yaw angle of the face\n",
    "    if the yaw angle is less than 30 degrees it will consider the face as frontal\n",
    "    if the yaw angle is more than 30 degrees it will consider the face as side face\n",
    "    it will also use a Kalman filter to smooth the yaw angle\n",
    "    then if the face is frontal it will crop the eyes and eyebrows\n",
    "    \"\"\"\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        \"\"\"\n",
    "        in this part we will detect the face landmarks\n",
    "        and calculate the yaw angle of the face\n",
    "        \"\"\"\n",
    "        landmarks = predictor(gray, face)\n",
    "        nose = (landmarks.part(30).x, landmarks.part(30).y)\n",
    "        left_ear = (landmarks.part(1).x, landmarks.part(1).y)\n",
    "        right_ear = (landmarks.part(15).x, landmarks.part(15).y)\n",
    "\n",
    "        # Calculate the distance from the nose to both ears\n",
    "        left_distance = np.linalg.norm(np.array(nose) - np.array(left_ear))\n",
    "        right_distance = np.linalg.norm(np.array(nose) - np.array(right_ear))\n",
    "        \n",
    "        # Calculate yaw using ratio of distances\n",
    "        yaw_ratio = right_distance / (left_distance + right_distance)\n",
    "        yaw_angle = (yaw_ratio - 0.5) * 90  # Convert ratio to degrees (-45 to 45)\n",
    "        yaw_angle = kalman_filter.update(yaw_angle)  # Apply Kalman filter\n",
    "\n",
    "        # Determine face orientation\n",
    "        if abs(yaw_angle) < 30:\n",
    "            face_orientation = \"Frontal Face\"\n",
    "            left_eye_pts = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(17, 22)] +  # Left eyebrow\n",
    "                                    [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]+  # Left eye\n",
    "                                    [(landmarks.part(n).x, landmarks.part(n).y) for n in range(28, 31)])  \n",
    "                                    \n",
    "            right_eye_pts = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(22, 27)] +  # Right eyebrow\n",
    "                                    [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]+  # Right eye\n",
    "                                    [(landmarks.part(n).x, landmarks.part(n).y) for n in range(29, 31)]\n",
    "                                    )  \n",
    "            x_left, y_left, w_left, h_left = cv2.boundingRect(left_eye_pts)\n",
    "            x_right, y_right, w_right, h_right = cv2.boundingRect(right_eye_pts)\n",
    "            expand_ratio = 0.2\n",
    "            h_expand = int(h_left * expand_ratio)  \n",
    "            y_left = max(y_left - h_expand, 0)\n",
    "            h_left = min(h_left + h_expand, img.shape[0] - y_left)\n",
    "            y_right = max(y_right - h_expand, 0)\n",
    "            h_right = min(h_right + h_expand, img.shape[0] - y_right)\n",
    "\n",
    "            \"\"\"\n",
    "            here we are cropping the eyes from the image\n",
    "            and saving them to the archive folder\n",
    "            \"\"\"\n",
    "            left_eye = img[y_left:y_left+h_left, x_left:x_left+w_left]\n",
    "            right_eye = img[y_right:y_right+h_right, x_right:x_right+w_right]\n",
    "            cv2.imwrite(\"archive/person_eye_left.jpg\", left_eye)\n",
    "            cv2.imwrite(\"archive/person_eye_right.jpg\", right_eye)\n",
    "            cv2.rectangle(img, (x_left, y_left), (x_left + w_left, y_left + h_left), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x_right, y_right), (x_right + w_right, y_right + h_right), (0, 255, 0), 2)\n",
    "\n",
    "            \"\"\"\n",
    "            then we will pass the cropped eyes to the loaded SVM model\n",
    "            to predict if the eyes are open or closed\n",
    "            \"\"\"\n",
    "            try:\n",
    "                left_eye_class = predict_image_fromPath(\"archive/person_eye_left.jpg\", loaded_model, class_mapping)\n",
    "                right_eye_class = predict_image_fromPath(\"archive/person_eye_right.jpg\", loaded_model, class_mapping)\n",
    "            except:\n",
    "                print(\"Error in prediction\")\n",
    "                continue\n",
    "\n",
    "            \"\"\"\n",
    "            in this part of the code we will check if the eyes are closed or open\n",
    "            if both eyes are closed we will start timing the closed eyes\n",
    "            else if one of the eyes is opened then the eyes are considered open\n",
    "            if the eyes are closed for more than 3 seconds we will beep a sound\n",
    "            if the eyes are open for more than 1 second we will reset the closed eyes timer\n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            we are checking the classes of the left and right eyes if there are both closed\n",
    "            \"\"\"\n",
    "            if left_eye_class == \"Close-Eyes\" and right_eye_class == \"Close-Eyes\":\n",
    "                print(\"Close-Eyes\")\n",
    "                if closed_eye_start_time is None:\n",
    "                    closed_eye_start_time = time.time()\n",
    "                \n",
    "                # Calculate duration of closed eyes\n",
    "                closed_eye_duration = time.time() - closed_eye_start_time\n",
    "                # here we checks if closed eye duration exceeds threshold\n",
    "                if closed_eye_duration >= CLOSED_EYE_THRESHOLD:\n",
    "                    print(f\"Eyes closed for {closed_eye_duration:.2f} seconds\")\n",
    "                    winsound.Beep(2500, 1000)  \n",
    "                    # Resetting timing parameters\n",
    "                    open_eye_start_time = None\n",
    "                    open_eye_duration = 0\n",
    "                    side_face_start_time = None\n",
    "                    side_face_duration = 0\n",
    "\n",
    "            else:\n",
    "                \"\"\"\n",
    "                here we are checking if the eyes are open\n",
    "                then reseting the closed eye timer\n",
    "                \"\"\"\n",
    "                \n",
    "                print(f\"Eyes open for {open_eye_duration:.2f} seconds\")\n",
    "                # Start or continue timing open eyes\n",
    "                if open_eye_start_time is None:\n",
    "                    open_eye_start_time = time.time()\n",
    "                # Calculate duration of open eyes\n",
    "                open_eye_duration = time.time() - open_eye_start_time\n",
    "                # Check if open eye duration exceeds threshold\n",
    "                if open_eye_duration >= OPEN_EYE_THRESHOLD:  \n",
    "                    # Reseting Timing Parameters\n",
    "                    closed_eye_start_time = None\n",
    "                    closed_eye_duration = 0\n",
    "                    side_face_start_time = None\n",
    "                    side_face_duration = 0\n",
    "\n",
    "        else:\n",
    "            \"\"\"\n",
    "            here we are checking if the face is turned to the side\n",
    "            if the yaw angle is more than 30 degrees\n",
    "            we will start timing the side face\n",
    "            \"\"\"\n",
    "            face_orientation = \"Side Face\"\n",
    "            if side_face_start_time is None:\n",
    "                side_face_start_time = time.time()\n",
    "            side_face_duration = time.time() - side_face_start_time\n",
    "            if side_face_duration >= SIDE_FACE_THRESHOLD:\n",
    "                print(f\"Face turned to the side for {side_face_duration:.2f} seconds\")\n",
    "                winsound.Beep(2500, 1000)\n",
    "                # Resetting timers\n",
    "                open_eye_start_time = None\n",
    "                open_eye_duration = 0\n",
    "                closed_eye_start_time = None\n",
    "                closed_eye_duration = 0\n",
    "\n",
    "        \n",
    "        print(f\"Face Orientation: {face_orientation} (Yaw: {yaw_angle:.2f}°)\")\n",
    "        cv2.putText(img, face_orientation, (face.left(), face.top() - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # Show real-time webcam feed\n",
    "    cv2.imshow(\"Driver Monitoring\", img)\n",
    "    \n",
    "    # Press `Esc` to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Close-Eyes\n",
      "Predicted Class: Open-Eyes\n"
     ]
    }
   ],
   "source": [
    "test = predict_image_fromPath(\"archive/person_eye_left.jpg\", loaded_model, class_mapping)\n",
    "print(f\"Predicted Class: {test}\")\n",
    "test = predict_image_fromPath(\"archive/person_eye_right.jpg\", loaded_model, class_mapping)\n",
    "print(f\"Predicted Class: {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Importing Required Libraries ===\n",
    "# These libraries provide tools for image processing, machine learning, and face landmark detection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2  # OpenCV for real-time image processing\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog  # For HOG feature extraction\n",
    "from skimage import data, exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle  # To load pre-trained model and class labels\n",
    "import dlib  # For facial landmark detection\n",
    "import time  # To measure time intervals for sleep detection\n",
    "import winsound  # For beeping alerts (works on Windows)\n",
    "\n",
    "# === Image Preprocessing Function ===\n",
    "def preprocess_image_fromPath(image_path, target_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Loads an image from disk, converts it to grayscale, smooths it,\n",
    "    resizes it, and normalizes the pixel values for feature extraction.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian and Median Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    filtered = cv2.medianBlur(blurred, 3)\n",
    "\n",
    "    # Resize to target size (64x64)\n",
    "    resized = cv2.resize(filtered, target_size)\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    normalized = resized / 255.0\n",
    "    return normalized\n",
    "\n",
    "# === HOG Feature Extraction Function ===\n",
    "def extract_hog_features(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "    \"\"\"\n",
    "    Extract Histogram of Oriented Gradients (HOG) features from an image.\n",
    "    \"\"\"\n",
    "    hog_features = hog(image, orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm='L2-Hys', visualize=False)\n",
    "    return hog_features\n",
    "\n",
    "# === Load Pretrained SVM Model and Class Mapping ===\n",
    "# Load the class mapping: {'Open-Eyes': 1, 'Close-Eyes': 0}\n",
    "pickle_in = open(\"class_mapping.pickle\", \"rb\")\n",
    "class_mapping = pickle.load(pickle_in)\n",
    "\n",
    "# Load trained SVM model for eye classification\n",
    "filename = 'SVM_model.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# === Image Classification Function ===\n",
    "def predict_image_fromPath(image_path, model, class_mapping, target_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Predict the class of a given image using the SVM model and return class name.\n",
    "    \"\"\"\n",
    "    preprocessed_image = preprocess_image_fromPath(image_path, target_size)\n",
    "    feature_vector = extract_hog_features(preprocessed_image).reshape(1, -1)\n",
    "    prediction = model.predict(feature_vector)[0]\n",
    "    \n",
    "    # Convert class index to class name using class_mapping\n",
    "    for class_name, label in class_mapping.items():\n",
    "        if label == prediction:\n",
    "            return class_name\n",
    "\n",
    "# === Kalman Filter Class to Smooth Head Pose Angles ===\n",
    "class KalmanFilter:\n",
    "    \"\"\"\n",
    "    Applies a Kalman filter to smooth noisy yaw angle values over time.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.kalman = cv2.KalmanFilter(2, 1)  # 2 state variables, 1 measurement\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 1], [0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.array([[1, 0], [0, 1e-5]], np.float32)\n",
    "        self.kalman.statePre = np.array([[0], [0]], np.float32)\n",
    "\n",
    "    def update(self, measurement):\n",
    "        prediction = self.kalman.predict()\n",
    "        estimate = self.kalman.correct(np.array([[measurement]], np.float32))\n",
    "        return estimate[0][0]\n",
    "\n",
    "# === Quick Test ===\n",
    "# Test the classifier on a sample image\n",
    "image_path = r\"D:\\CUFE\\GP\\Sleep_detection\\archive\\open_eye.jpg\"\n",
    "predicted_class = predict_image_fromPath(image_path, loaded_model, class_mapping)\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "# === Time Thresholds and State Variables for Monitoring ===\n",
    "closed_eye_start_time = None\n",
    "closed_eye_duration = 0\n",
    "CLOSED_EYE_THRESHOLD = 3  # Raise alert if eyes closed for >= 3 seconds\n",
    "\n",
    "open_eye_start_time = None\n",
    "open_eye_duration = 0\n",
    "OPEN_EYE_THRESHOLD = 1  # Reset states if eyes open for >= 1 second\n",
    "\n",
    "side_face_start_time = None\n",
    "side_face_duration = 0\n",
    "SIDE_FACE_THRESHOLD = 3  # Raise alert if face turned for >= 3 seconds\n",
    "\n",
    "# === Facial Landmark Detection Setup ===\n",
    "# Load dlib’s face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# === Start Webcam Capture ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create instance of the Kalman filter\n",
    "kalman_filter = KalmanFilter()\n",
    "\n",
    "# === Main Loop for Real-time Monitoring ===\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for facial detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        # Get facial landmarks (68 points)\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Extract nose and ears to estimate face yaw (left/right orientation)\n",
    "        nose = (landmarks.part(30).x, landmarks.part(30).y)\n",
    "        left_ear = (landmarks.part(1).x, landmarks.part(1).y)\n",
    "        right_ear = (landmarks.part(15).x, landmarks.part(15).y)\n",
    "\n",
    "        # Estimate yaw angle based on distances from nose to ears\n",
    "        left_distance = np.linalg.norm(np.array(nose) - np.array(left_ear))\n",
    "        right_distance = np.linalg.norm(np.array(nose) - np.array(right_ear))\n",
    "        yaw_ratio = right_distance / (left_distance + right_distance)\n",
    "        yaw_angle = (yaw_ratio - 0.5) * 90  # Approximate -45 to 45°\n",
    "        yaw_angle = kalman_filter.update(yaw_angle)  # Smooth it\n",
    "\n",
    "        # --- Check if face is forward or turned sideways ---\n",
    "        if abs(yaw_angle) < 30:\n",
    "            face_orientation = \"Frontal Face\"\n",
    "\n",
    "            # Extract eye region coordinates from landmarks\n",
    "            left_eye_pts = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)])\n",
    "            right_eye_pts = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)])\n",
    "\n",
    "            # Get bounding box for both eyes\n",
    "            x_left, y_left, w_left, h_left = cv2.boundingRect(left_eye_pts)\n",
    "            x_right, y_right, w_right, h_right = cv2.boundingRect(right_eye_pts)\n",
    "\n",
    "            # Slightly expand bounding box to include full eye\n",
    "            expand_ratio = 0.2\n",
    "            h_expand = int(h_left * expand_ratio)\n",
    "            y_left = max(y_left - h_expand, 0)\n",
    "            h_left = min(h_left + h_expand, img.shape[0] - y_left)\n",
    "            y_right = max(y_right - h_expand, 0)\n",
    "            h_right = min(h_right + h_expand, img.shape[0] - y_right)\n",
    "\n",
    "            # Crop eye images from original frame\n",
    "            left_eye = img[y_left:y_left+h_left, x_left:x_left+w_left]\n",
    "            right_eye = img[y_right:y_right+h_right, x_right:x_right+w_right]\n",
    "\n",
    "            # Save temporary images of the eyes\n",
    "            cv2.imwrite(\"archive/person_eye_left.jpg\", left_eye)\n",
    "            cv2.imwrite(\"archive/person_eye_right.jpg\", right_eye)\n",
    "\n",
    "            # Draw rectangles for visualization\n",
    "            cv2.rectangle(img, (x_left, y_left), (x_left + w_left, y_left + h_left), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x_right, y_right), (x_right + w_right, y_right + h_right), (0, 255, 0), 2)\n",
    "\n",
    "            # Predict if eyes are open or closed\n",
    "            try:\n",
    "                left_eye_class = predict_image_fromPath(\"archive/person_eye_left.jpg\", loaded_model, class_mapping)\n",
    "                right_eye_class = predict_image_fromPath(\"archive/person_eye_right.jpg\", loaded_model, class_mapping)\n",
    "            except:\n",
    "                print(\"Error in prediction\")\n",
    "                continue\n",
    "\n",
    "            # === Both Eyes Closed ===\n",
    "            if left_eye_class == \"Close-Eyes\" and right_eye_class == \"Close-Eyes\":\n",
    "                print(\"Close-Eyes\")\n",
    "                if closed_eye_start_time is None:\n",
    "                    closed_eye_start_time = time.time()\n",
    "                closed_eye_duration = time.time() - closed_eye_start_time\n",
    "\n",
    "                if closed_eye_duration >= CLOSED_EYE_THRESHOLD:\n",
    "                    print(f\"Eyes closed for {closed_eye_duration:.2f} seconds\")\n",
    "                    winsound.Beep(2500, 1000)  # Beep alert\n",
    "                    # Reset other timers\n",
    "                    open_eye_start_time = None\n",
    "                    open_eye_duration = 0\n",
    "                    side_face_start_time = None\n",
    "                    side_face_duration = 0\n",
    "\n",
    "            # === Eyes Open ===\n",
    "            else:\n",
    "                print(f\"Eyes open for {open_eye_duration:.2f} seconds\")\n",
    "                if open_eye_start_time is None:\n",
    "                    open_eye_start_time = time.time()\n",
    "                open_eye_duration = time.time() - open_eye_start_time\n",
    "\n",
    "                if open_eye_duration >= OPEN_EYE_THRESHOLD:\n",
    "                    # Reset closed eye and side face timers\n",
    "                    closed_eye_start_time = None\n",
    "                    closed_eye_duration = 0\n",
    "                    side_face_start_time = None\n",
    "                    side_face_duration = 0\n",
    "\n",
    "        # === Face Turned Away (Yaw > 30°) ===\n",
    "        else:\n",
    "            face_orientation = \"Side Face\"\n",
    "            if side_face_start_time is None:\n",
    "                side_face_start_time = time.time()\n",
    "            side_face_duration = time.time() - side_face_start_time\n",
    "\n",
    "            if side_face_duration >= SIDE_FACE_THRESHOLD:\n",
    "                print(f\"Face turned for {side_face_duration:.2f} seconds\")\n",
    "                winsound.Beep(2500, 1000)  # Alert\n",
    "                # Reset other timers\n",
    "                open_eye_start_time = None\n",
    "                open_eye_duration = 0\n",
    "                closed_eye_start_time = None\n",
    "                closed_eye_duration = 0\n",
    "\n",
    "        # Show orientation text on screen\n",
    "        print(f\"Face Orientation: {face_orientation} (Yaw: {yaw_angle:.2f}°)\")\n",
    "        cv2.putText(img, face_orientation, (face.left(), face.top() - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # === Display Webcam Frame ===\n",
    "    cv2.imshow(\"Driver Monitoring\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press ESC to exit\n",
    "        break\n",
    "\n",
    "# === Cleanup ===\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
